<?xml version="1.0" encoding="UTF-8"?><process version="10.5.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="10.5.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="python_scripting:python_transformer" compatibility="10.1.002" expanded="true" height="68" name="Start Flink Job (SSH)" width="90" x="447" y="85">
        <parameter key="editable" value="false"/>
        <parameter key="operator" value="{&#13;&#10;  &quot;name&quot; : &quot;Start Flink Job (SSH)&quot;,&#13;&#10;  &quot;dropSpecial&quot; : true,&#13;&#10;  &quot;parameters&quot; : [ {&#13;&#10;    &quot;name&quot; : &quot;docker_container_name&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;Docker container name on remote&quot;,&#13;&#10;    &quot;value&quot; : &quot;flink-2-flink-2-jm-1&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;ssh_host_name&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;SSH connection server name&quot;,&#13;&#10;    &quot;value&quot; : &quot;server\.crexdata\.eu&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;ssh_user_name&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;SSH connection user name&quot;,&#13;&#10;    &quot;value&quot; : &quot;ubuntu&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;flink_job_name&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;Name of flink job&quot;,&#13;&#10;    &quot;value&quot; : &quot;relevance-prediction-job-test-async&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;kafka_server&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;Kafka boostrap server and port&quot;,&#13;&#10;    &quot;value&quot; : &quot;server\.crexdata\.eu:9092&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;input_topic&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;Input kafka topic with tweets&quot;,&#13;&#10;    &quot;value&quot; : &quot;input&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;output_topic&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;Output kafka topic after processing&quot;,&#13;&#10;    &quot;value&quot; : &quot;output&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;filtered_topic&quot;,&#13;&#10;    &quot;type&quot; : &quot;string&quot;,&#13;&#10;    &quot;description&quot; : &quot;Output kafka topic to send filtered tweet with detected events&quot;,&#13;&#10;    &quot;value&quot; : &quot;mytopik3&quot;&#13;&#10;  }, {&#13;&#10;    &quot;name&quot; : &quot;offset_type&quot;,&#13;&#10;    &quot;type&quot; : &quot;category&quot;,&#13;&#10;    &quot;description&quot; : &quot;Use 'earliest' to process a whole topic from the beginning and 'latest' for new incoming messages\.&quot;,&#13;&#10;    &quot;categories&quot; : [ &quot;latest&quot;, &quot;earliest&quot; ],&#13;&#10;    &quot;value&quot; : &quot;latest&quot;&#13;&#10;  } ],&#13;&#10;  &quot;inputs&quot; : [ {&#13;&#10;    &quot;name&quot; : &quot;sshkey&quot;,&#13;&#10;    &quot;type&quot; : &quot;file&quot;&#13;&#10;  } ]&#13;&#10;}.import paramiko&#10;&#10;&#10;def rm_main(key, parameters):&#10;&#9;key_file_path = key\.name&#10;&#9;print(key_file_path)&#10;&#9;&#10;&#9;# The command you want to execute on the remote server&#10;&#9;remote_command = f&quot;docker exec {parameters['docker_container_name']} bash -c 'flink run -d -py /mnt/relevance_job_utils/relevance-job-testing-async\.py --jarfile /mnt/relevance_job_utils/flink-sql-connector-kafka-4\.0\.0-2\.0\.jar &quot; +\\&#10;&#9;f&quot;--kafka-server {parameters['kafka_server']} &quot; +\\&#10;&#9;f&quot;--input-topic {parameters['input_topic']} &quot; +\\&#10;&#9;f&quot;--output-topic {parameters['output_topic']} &quot; +\\&#10;&#9;f&quot;--output-filtered {parameters['filtered_topic']} &quot; +\\&#10;&#9;f&quot;--job-name {parameters['flink_job_name']} &quot; +\\&#10;&#9;f&quot;--offset-type {parameters['offset_type']}'&quot;&#10;&#10;&#9;private_key = paramiko\.RSAKey\.from_private_key_file(key_file_path)&#10;&#9;&#10;&#9;# Establish an SSH connection&#10;&#9;ssh = paramiko\.SSHClient()&#10;&#9;ssh\.set_missing_host_key_policy(paramiko\.AutoAddPolicy())&#10;&#9;ssh\.connect(parameters['ssh_host_name'], username=parameters['ssh_user_name'], pkey=private_key)&#10;&#9;&#10;&#9;# Execute the remote command&#10;&#9;_, stdout, stderr = ssh\.exec_command(remote_command)&#10;&#9;print(&quot;Output of the remote command:&quot;)&#10;&#10;&#9;print(f&quot;stdout:\\n {stdout\.read()\.decode()}&quot;)&#10;&#9;ssh\.close()&#10;"/>
        <parameter key="use_default_python" value="false"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="conda_environment" value="rm_genai"/>
        <parameter key="docker_container_name" value="flink-2-flink-2-jm-1"/>
        <parameter key="ssh_host_name" value="server.crexdata.eu"/>
        <parameter key="ssh_user_name" value="ubuntu"/>
        <parameter key="flink_job_name" value="relevance-prediction-job-test-async"/>
        <parameter key="kafka_server" value="server.crexdata.eu:9092"/>
        <parameter key="input_topic" value="input"/>
        <parameter key="output_topic" value="output"/>
        <parameter key="filtered_topic" value="mytopik3"/>
        <parameter key="offset_type" value="latest"/>
      </operator>
      <connect from_port="input 1" to_op="Start Flink Job (SSH)" to_port="sshkey"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="source_input 2" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <portSpacing port="sink_result 3" spacing="0"/>
    </process>
  </operator>
  <title>Text Mining Start Prediction Flink Job</title>
  <icon>server_into.png</icon>
  <description>It uses SSH and requires a pemission file to access the server. This operator should only be used with the flink server setup of the CREXDATA Text Mining solution. </description>
  <synopsis>This operator starts a remote flink job for event type prediction in a docker container.</synopsis>
  <number-of-inputs>1</number-of-inputs>
  <number-of-outputs>0</number-of-outputs>
  <defines-optionals>true</defines-optionals>
  <param-ordering>true</param-ordering>
  <gets-random-seed>true</gets-random-seed>
  <custom-operator-type>standard</custom-operator-type>
  <template-parameters>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>use_default_python</parameter>
      <alias>use_default_python</alias>
      <documentation>Use the default environment, as specified in the Preferences.</documentation>
      <optional>true</optional>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>package_manager</parameter>
      <alias>package_manager</alias>
      <documentation>Python package manager framework.</documentation>
      <dependency>
        <parameter-alias>use_default_python</parameter-alias>
        <parameter-value>false</parameter-value>
      </dependency>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>conda_environment</parameter>
      <alias>conda_environment</alias>
      <documentation>Conda environment</documentation>
      <dependency>
        <parameter-alias>use_default_python</parameter-alias>
        <parameter-value>false</parameter-value>
      </dependency>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>docker_container_name</parameter>
      <alias>docker_container_name</alias>
      <documentation>Docker container name on remote</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>ssh_host_name</parameter>
      <alias>ssh_host_name</alias>
      <documentation>SSH connection server name</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>ssh_user_name</parameter>
      <alias>ssh_user_name</alias>
      <documentation>SSH connection user name</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>flink_job_name</parameter>
      <alias>flink_job_name</alias>
      <documentation>Name of flink job</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>kafka_server</parameter>
      <alias>kafka_server</alias>
      <documentation>Kafka boostrap server and port</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>input_topic</parameter>
      <alias>input_topic</alias>
      <documentation>Input kafka topic with tweets</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>output_topic</parameter>
      <alias>output_topic</alias>
      <documentation>Output kafka topic after processing</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>filtered_topic</parameter>
      <alias>filtered_topic</alias>
      <documentation>Output kafka topic to send filtered tweet with detected events</documentation>
    </template-parameter>
    <template-parameter>
      <operator>Start Flink Job (SSH)</operator>
      <parameter>offset_type</parameter>
      <alias>offset_type</alias>
      <documentation>Use 'earliest' to process a whole topic from the beginning and 'latest' for new incoming messages.</documentation>
    </template-parameter>
  </template-parameters>
  <input-docu>
    <port>
      <type>com.rapidminer.operator.IOObject</type>
      <description>SSH permission file location</description>
    </port>
  </input-docu>
  <tutorials/>
  <input-port-names>ssh</input-port-names>
</process>
